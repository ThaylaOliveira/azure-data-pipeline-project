## Projeto de AnÃ¡lise e TransformaÃ§Ã£o de Dados com Azure Data Factory e Data Flow


#### Status: â³ Em progresso

---

### ğŸš€ VisÃ£o Geral

Este projeto simula um ambiente corporativo de engenharia e anÃ¡lise de dados utilizando Microsoft Azure, com foco na construÃ§Ã£o de pipelines para ingestÃ£o, transformaÃ§Ã£o e armazenamento de dados.

Utilizamos Azure Data Factory para orquestraÃ§Ã£o e Azure Data Flow (Spark) para transformaÃ§Ã£o dos dados, organizando os dados nas camadas Bronze, Silver e Gold.

---

### ğŸ¯ Objetivos de aprendizagem

- Simular um ambiente de dados corporativo real
- Aprender o fluxo de ingestÃ£o e tratamento em camadas
- Aplicar boas prÃ¡ticas de arquitetura em nuvem
- Documentar e versionar o projeto para portfÃ³lio

---

### ğŸ—‚ Estrutura dos Dados

- **Camada Bronze:** dados brutos importados diretamente dos arquivos CSV originais.
- **Camada Silver:** dados limpos e estruturados, com tratamentos e ajustes.
- **Camada Gold:** dados transformados, agregados e prontos para anÃ¡lise e consumo, armazenados em arquivos CSV Ãºnicos.

---

## ğŸ“ Dados Utilizados

Os dados utilizados sÃ£o arquivos CSV simulando dados de pedidos, clientes, produtos, pagamentos, geolocalizaÃ§Ã£o e avaliaÃ§Ãµes, com schemas interligados.

---

### âš™ï¸ Tecnologias e Ferramentas

- Microsoft Azure Data Factory (ADF)
- Azure Blob Storage (para armazenar arquivos CSV)
- Azure Portal para gerenciamento
-  Azure Data Flow (Spark)
- GitHub para versionamento e documentaÃ§Ã£o

---

### ğŸ”§ Passos para Reproduzir o Projeto

1. Criar Storage Account no Azure e configurar containers para Bronze, Silver e Gold.
2. Criar datasets no ADF apontando para os arquivos CSV em cada camada.
3. Criar pipelines no ADF com Data Flows para realizar joins e transformaÃ§Ãµes.
4. Configurar parÃ¢metros para flexibilizar caminhos e nomes de arquivos.
5. Executar pipelines e verificar arquivos transformados na camada Gold.
6. Opcional: conectar ferramentas de BI (ex: Power BI) para anÃ¡lise.

---

### ğŸ“ Sobre a TransformaÃ§Ã£o Principal

- Data Flow que realiza join entre as tabelas `orders` e `customers`.
- Produz um CSV Ãºnico (`pedidos_com_clientes.csv`) na camada Gold.
- ParÃ¢metros configurados para permitir reuso e escalabilidade.

---

### ğŸ’¡ ObservaÃ§Ãµes

- O Data Flow foi configurado para usar â€œSingle partitionâ€ para gerar um Ãºnico arquivo CSV.
- O projeto pode ser expandido para incluir outras tabelas e transformaÃ§Ãµes.
- Ideal para aprendizado prÃ¡tico de pipelines de dados no Azure.

---
## âœ¨ Autora

Thayla Oliveira  
[LinkedIn](https://linkedin.com/in/thayla-oliveira) | [Email](thaylathais1@gmail.com)

